{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB0enqgBgefd"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CienciaDatosUdea/002_EstudiantesAprendizajeEstadistico/blob/main/semestre2024-2/Laboratorios/Laboratorio_01_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Laboratorio 1.0: \n",
    "\n",
    "## Series de tiempo\n",
    "\n",
    "El siguiente [dataset](https://raw.githubusercontent.com/hernansalinas/Curso_aprendizaje_estadistico/main/datasets/Pandas_data_historical_dataEURUSD.csv) contiene información del precio del eur/usd  desde el 05/07/2022/ hasta el 12/05/2023 con periodicidad de una hora. El data frame contiene el precio de apertura, cierrre, valor más bajo cotizado, valor más alto cotizado, volumen, spread etc. Para este dataset, realizar lo siguiente:\n",
    "\n",
    "\n",
    "1. Leer el dataset desde el github.\n",
    "2. Definir como indice la columna time.\n",
    "3. Obtenga información del data frame.\n",
    "\n",
    "4. Determine si hay null, nan en el data frame.\n",
    "\n",
    "5. Emplea la notacion Pascal Case y trabaja solo con la columa del precio de cierre del eur/usd.  \n",
    "\n",
    "6. Ahora vamos a determinar cual es la mejor distribución estadística que se ajusta a la diferencia del precio de cierre cada hora, para ello realizamos lo siguiente:\n",
    "- Determine la diferencia de precio entre horas, agregue una nueva columna llamada DiffPrice, en este punto tu dataframe debe tener solo dos columnas Close, DiffPrice y el indice debe ser el tiempo.\n",
    "- Para la nueva columna construya un histograma de los datos.\n",
    "- Determine la mejor distribucion estadística que se ajusta al histograma anterior, para ello puede emplear lo siguente:\n",
    "\n",
    "\n",
    "https://pypi.org/project/fitter/\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "f = Fitter(data,\n",
    "           distributions=['gamma',\n",
    "                          'lognorm',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()\n",
    "f.summary()\n",
    "#Indentificamos la mejor distribucion con el error cuadratico medio\n",
    "f.get_best(method = 'sumsquare_error')\n",
    "#Indentificamos parametros de la distrubicion beta\n",
    "f.fitted_param[\"beta\"]\n",
    "\n",
    "```\n",
    "\n",
    "Con el metodo get_distributions(), podemos ver todas las distribuciones estadisticas de la libreria. Ajusta a la mejor.  Puede consultar [esta](https://medium.com/the-researchers-guide/finding-the-best-distribution-that-fits-your-data-using-pythons-fitter-library-319a5a0972e9)  página si desea ver un ejemplo.\n",
    "\n",
    "\n",
    "7. Para el data frame, seleccionemos solo los datos del 2023.\n",
    "\n",
    "8. El comando groupby permite agrupar los datos con la periodicidad deseada: 1 dias, 2 dias, 1 mes etc. Determina el promedio con una periodicidad de 15 dias, con periodidicidad de 1 semana, y una periodicidad de 1 mes\n",
    "\n",
    "```python\n",
    "  df.groupby(pd.Grouper(key='time', freq='15D')).mean()\n",
    "```\n",
    "\n",
    "9. Para los datos asociados a los meses de 2023, construya un histograma para cada mes.  Para ello puedo emplear el metodo groupby. Notetese que si no  realiza una operación después de aplicar el metodo grouby, podrias iterar sobre dicho objeto, por ejemplo:\n",
    "\n",
    "```python\n",
    "q=df.groupby(pd.Grouper(key='time', freq='15D'))\n",
    "\n",
    "for name, group in q:\n",
    "  print(name, group)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzhBd58dWJXq"
   },
   "source": [
    "Para el dataset realizar lo siguiente:\n",
    "\n",
    "1. Leer los datos desde la página web\n",
    "\n",
    "2. Renombrar las columnas en PascalCase\n",
    "  Ejemplo: La columna radius_worst, concave points_se deberia llamar: RadiusWorst, ConcavePointsSe\n",
    "\n",
    "3. Emplear los metodos head, tail, describe,info para obtener información acerca del dataframe,\n",
    "\n",
    "4. Contabilizar la cantidad de null or nan en el dataframe, si hay null, ¿que valor se puede tomar para reemplazar los datos?\n",
    "\n",
    "5. Encontrar los valores  diferentes en el target, mostrar que es B y M. Emplear el metodo unique.\n",
    "\n",
    "6. Empleando la libreria seaborn y el metodo countplot, realice un conteo de las personas que tiene la etiqueta B y M.\n",
    "\n",
    "  ```python\n",
    "  import seaborn as sns\n",
    "  sns.countplot?\n",
    "  ```\n",
    "\n",
    "7. Agregar una nueva columna llamada DiagnosisNumeric, en la que cada valor B, M se corresponde con un valor 0, 1 respectivamente.\n",
    "\n",
    "8. Normalizar cada columna respecto a su media y desviación estandar: (x-mean(x))/std(x)\n",
    "\n",
    "9. Realizar un promedio de todas las características similares, llamelas: \n",
    "\n",
    "```python\n",
    "['RadiusMean', 'TextureMean', 'PerimeterMean', 'AreaMean','SmoothnessMean', 'CompactnessMean', 'ConcavityMean','ConcavePointsMean',\"SymetryMean\",\"FractalDimensionMean\"]\n",
    "```\n",
    "\n",
    "Para encontrar las características similares, radius1, radius2, radius3 y tomar los promedios puede emplear expresiones regulares como:\n",
    "\n",
    "```python \n",
    "re.match(r'^[a-zA-Z_]+', \"holamundo12341\").group(0)\n",
    "```\n",
    "\n",
    "con base a lo anterior forme los patrones a buscar, es decir: \n",
    "\n",
    "```python \n",
    "[Radius, Texture, Perimeter, ...]\n",
    "```\n",
    " y con base en ello, emplee el metodo `startwith` para un string.  \n",
    "\n",
    "\n",
    "\n",
    "10. En un mismo gráfico mostrar el histograma de la columna RadiusMean  para la etiqueta B y M en color naranja y azul de la columna Diagnosis respectivamente.\n",
    "\n",
    "11. Para las columnas:\n",
    "```python\n",
    "['RadiusMean', 'TextureMean', 'PerimeterMean', 'AreaMean','SmoothnessMean', 'CompactnessMean', 'ConcavityMean','ConcavePointsMean',\"symmetry3\",\"fractal_dimension3\"]```\n",
    "\n",
    "realizar multiples histograma en un gráfico de [violin](https://seaborn.pydata.org/generated/seaborn.violinplot.html).\n",
    "\n",
    "```python\n",
    "data = pd.melt(df.iloc[:, 0:10], id_vars=\"Diagnosis\",var_name=\"features\",value_name=\"value\")\n",
    "sns.violinplot(x=\"features\",y=\"value\",  hue=\"Diagnosis\",data=data, split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=45)\n",
    "```\n",
    "\n",
    "10. Determinar los datos [outlier](https://en.wikipedia.org/wiki/Outlier)  para la columna RadiusMean y eliminarlos del data frame, para ello construya un gráfico tipo [boxplot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html)\n",
    "\n",
    "\n",
    "```\n",
    "df.boxplot(column=\"RadiusMean\", by='Diagnosis', sym = 'k.', figsize=(18,6))\n",
    "```\n",
    "\n",
    "¿Qué informacion podemos obtener de este tipo de gráficos?\n",
    "\n",
    "\n",
    "Usar el rango intercuartílico (IQR): El IQR es la diferencia entre el tercer y el primer cuartil de los datos, es decir, el 75% y el 25% de los valores ordenados. Los valores que están fuera del rango [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] se consideran outliers y se pueden eliminar o reemplazar. Por ejemplo, si queremos eliminar los outliers de una columna llamada 'edad' usando el IQR, podemos hacer lo siguiente\n",
    "\n",
    "```python\n",
    "Q1 = df['edad'].quantile(0.25)\n",
    "Q3 = df['edad'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df['edad'] < (Q1 - 1.5 * IQR)) | (df['edad'] > (Q3 + 1.5 * IQR)))]\n",
    "```\n",
    "\n",
    "Otra forma de determinar los outlier es con el puntaje Z:\n",
    "El puntaje Z es el número de desviaciones estándar que un valor está por encima o por debajo de la media. Los valores que tienen un puntaje Z mayor que un umbral (por ejemplo, 3) se consideran outliers y se pueden eliminar o reemplazar. Por ejemplo, si queremos eliminar los outliers de la columna 'edad' usando el puntaje Z, podemos hacer lo siguiente:\n",
    "\n",
    "```python\n",
    "df = df[(np.abs(stats.zscore(df['edad'])) < 3)]\n",
    "```\n",
    "\n",
    "En un problema de machine learning se debe elegir todas las columnas y construir un algoritmo que permite obtener la mejor calidad de los datos sobre todas las columnas.\n",
    "\n",
    "\n",
    "11. Encontrar la matrix de correlacion, emplear el metodo corr(), dentro de seaborn buscar el metodo heatmap() para realizar un grafico de la matrix de correlación.\n",
    "\n",
    "12. ¿Que otro tipo de gráficos pueden ser realizados para entender mejor los datos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg5T-MejYZf-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyhIUpJmfXQr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
